\documentclass[12pt]{article}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{fontspec}
\usepackage{xfrac}
\usepackage{array}
\usepackage{siunitx}
\usepackage{gensymb}
\usepackage{enumitem}
\usepackage{dirtytalk}
\usepackage{bm}
\title{Subspaces (exercises)}
\author{ZoÃ« Sparks}

\begin{document}

\theoremstyle{definition}

\sisetup{quotient-mode=fraction}
\newtheorem{thm}{Theorem}
\newtheorem*{nthm}{Theorem}
\newtheorem{sthm}{}[thm]
\newtheorem{lemma}{Lemma}[thm]
\newtheorem*{nlemma}{Lemma}
\newtheorem{cor}{Corollary}[thm]
\newtheorem*{prop}{Property}
\newtheorem*{defn}{Definition}
\newtheorem*{comm}{Comment}
\newtheorem*{exm}{Example}

\maketitle

\begin{enumerate}
  \item
    We would like to determine which of the following sets of vectors $\alpha =
    (a_1,\ldots,a_n)$ in $R^n$ are subspaces of $R^n (n \geq 3)$.
    \begin{enumerate}
      \item
        The set of all $\alpha$ such that $a_1 \geq 0$ is not, because if $a_1 > 0$
        and $c < 0$, then $ca_1 < 0$, so it's possible for $c\alpha =
        (ca_1,\ldots,ca_n)$ to be outside the set.

      \item
        The set of all $\alpha$ such that $a_1 + 3a_2 = a_3$ is:
        \begin{align*}
          c(a_1,a_2,a_1 + 3a_2,\ldots,a_n) + (b_1,b_2,b_1 + 3b_2,\ldots,b_n) &=\\
          (ca_1,ca_2,ca_1 + 3ca_2,\ldots,ca_n) + (b_1,b_2,b_1 + 3b_2,\ldots,b_n) &=\\
          (ca_1+b_1,\ ca_2+b_2,\ ca_1+b_1 + 3ca_2+3b_2,\ \ldots,\ ca_n + b_n) &=\\
          (ca_1+b_1,\ ca_2+b_2,\ (ca_1+b_1) + 3(ca_2+b_2),\ \ldots,\ ca_n + b_n).
        \end{align*}

      \item
        The set of all $\alpha$ such that $a_2 = a_1^2$ is not:
        \begin{align*}
          c(a_1,a_1^2,\ldots,a_n) + (b_1,b_1^2,\ldots,b_n) &=\\
          (ca_1,ca_1^2,\ldots,ca_n) + (b_1,b_1^2,\ldots,b_n) &=\\
          (ca_1+b_1,ca_1^2+b_1^2,\ldots,ca_n+b_n).
        \end{align*}
        $(ca_1+b_1)^2 = ca_1^2 + 2ca_1b_1 + b_1^2 \neq ca_1^2+b_1^2$ (well, unless
        $a,b = 0$).

      \item
        For the set of all $\alpha$ such that $a_1a_2 = 0$, we know by the definition
        of a field that for any given vector in the set, either $a_1 = 0$, $a_2 = 0$,
        or both. If one has $a_1 = 0,\ a_2 \neq 0$ and the other has $a_2 = 0,\ a_1
        \neq 0$, then
        \begin{align*}
          c(a_1,0,\ldots,a_n) + (0,b_2,\ldots,b_n) &=\\
          (ca_1,c0,\ldots,ca_n) + (0,b_2,\ldots,b_n) &=\\
          (ca_1,0,\ldots,ca_n) + (0,b_2,\ldots,b_n) &=\\
          (ca_1,b_2,\ldots,ca_n+b_n).
        \end{align*}
        So, this set is not.

      \item
        The set of all $\alpha$ such that $a_2$ is rational is not, because $R^n$ is
        over the real numbers, and some real numbers are irrational. If $c$ is an
        irrational real number, $ca_2$ will also be irrational unless $a_2 = 0$, so
        $c\alpha$ will be outside the set for some values of $c$.
    \end{enumerate}

    \item
      If $V$ is the real vector space of all functions $f$ from $R$ into $R$, we
      would like to determine which of the following sets are subspaces of $V$. In
      the following, let $f,g$ be members of the set in question and let $c$ be a
      real number.
      \begin{enumerate}
        \item
          The set of all $f$ such that $f(x^2) = f(x)^2$ is not. If
          \begin{align*}
            h(x) &= cf(x) + g(x),\\
            \shortintertext{then}
            h(x^2) &= cf(x^2) + g(x^2)\\
            &= cf(x)^2 + g(x)^2,\\
            \shortintertext{but}
            h(x)^2 = (cf(x) + g(x))^2 &= c^2f(x)^2 + 2cf(x)g(x) + g(x)^2.
          \end{align*}

        \item
          The set of all $f$ such that $f(0) = f(1)$ is. If
          \begin{align*}
            h(x) &= cf(x) + g(x),\\
            \shortintertext{then}
            h(0) &= cf(0) + g(0)\\
            &= cf(1) + g(1)\\
            \shortintertext{and}
            h(1) &= cf(1) + g(1).
          \end{align*}

        \item
          The set of all $f$ such that $f(3) = 1 + f(-5)$ is not. If
          \begin{align*}
            h(x) &= cf(x) + g(x),\\
            \shortintertext{then}
            h(3) &= cf(3) + g(3)\\
            &= 1 + cf(-5) + 1 + g(-5)\\
            &= 2 + cf(-5) + g(-5),
            \shortintertext{but}
            h(-5) &= cf(-5) + g(-5).
          \end{align*}

        \item
          The set of all $f$ such that $f(-1) = 0$ is. If
          \begin{align*}
            h(x) &= cf(x) + g(x),\\
            \shortintertext{then}
            h(-1) &= cf(-1) + g(-1)\\
            &= c0 + 0\\
            &= 0.
          \end{align*}

        \item
          The set of all continuous $f$ is, because if $f,g$ are continuous, $cf$ is
          continuous and $f + g$ is continuous, so $cf + g$ is continuous.
      \end{enumerate}

    \item
      We would like to determine if the vector $(3,-1,0,-1)$ is in the subspace of
      $R^5$ spanned by the vectors $(2,-1,3,2)$, $(-1,1,1,-3)$, and $(1,1,9,-5)$.

      The subspace of $R^5$ spanned by the vectors
      \begin{alignat*}{7}
        \alpha_1 &= (&2&,\ &-1&,\ &3&,\ &2&)\\
        \alpha_2 &= (&-1&,\ &1&,\ &1&,\ &-3&)\\
        \alpha_3 &= (&1&,\ &1&,\ &9&,\ &-5&)
      \end{alignat*}
      is the row space of the matrix
      \begin{align*}
        \begin{bmatrix}
          2  & -1 & 3 & 2  & 0\\
          -1 & 1  & 1 & -3 & 0\\
          1  & 1  & 9 & -5 & 0\\
        \end{bmatrix}.
      \end{align*}
      \begin{align*}
        \begin{bmatrix}
          2 & -1 & 3 & 2 & 0\\
          -1 & 1 & 1 & -3 & 0\\
          1 & 1 & 9 & -5 & 0
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          1 & -\frac{1}{2} & \frac{3}{2} & 1 & 0\\
          -1 & 1 & 1 & -3 & 0\\
          1 & 1 & 9 & -5 & 0
        \end{bmatrix}
        \xrightarrow{}
      \end{align*}
      \begin{align*}
        \begin{bmatrix}
          1 & -\frac{1}{2} & \frac{3}{2} & 1 & 0\\
          0 & \frac{1}{2} & \frac{5}{2} & -2 & 0\\
          1 & 1 & 9 & -5 & 0
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          1 & -\frac{1}{2} & \frac{3}{2} & 1 & 0\\
          0 & \frac{1}{2} & \frac{5}{2} & -2 & 0\\
          0 & \frac{3}{2} & \frac{15}{2} & -6 & 0
        \end{bmatrix}
        \xrightarrow{}
      \end{align*}
      \begin{align*}
        \begin{bmatrix}
          1 & -\frac{1}{2} & \frac{3}{2} & 1 & 0\\
          0 & 1 & 5 & -4 & 0\\
          0 & \frac{3}{2} & \frac{15}{2} & -6 & 0
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          1 & 0 & 4 & -1 & 0\\
          0 & 1 & 5 & -4 & 0\\
          0 & \frac{3}{2} & \frac{15}{2} & -6 & 0
        \end{bmatrix}
        \xrightarrow{}
      \end{align*}
      \begin{align*}
        \begin{bmatrix}
          1 & 0 & 4 & -1 & 0\\
          0 & 1 & 5 & -4 & 0\\
          0 & 0 & 0 & 0 & 0
        \end{bmatrix}.
      \end{align*}

      \begin{align*}
        \alpha = (c_1,c_2,4c_1+5c_2,-c_1-4c_2,0).
      \end{align*}

      \begin{align*}
        [2,\ -1,\ 4(2) + 5(-1), -2 -4(-1)] &=\\
        (2,\ -1,\ 8 - 5, -2 +4) &=\\
        (2,\ -1,\ 3, 2).\\\\
        [-1,\ 1,\ 4(-1) + 5(1),-(-1) - 4(1)] &=\\
        (-1,\ 1,\ -4 + 5,\ 1 - 4) &=\\
        (-1,\ 1,\ 1,\ -3).\\\\
        [1,\ 1,\ 4(1) + 5(1),\ -(1) - 4(1)] &=\\
        (1,\ 1,\ 4 + 5,\ -1 - 4) &=\\
        (1,\ 1,\ 9,\ -5).\\\\
        [3,\ -1,\ 4(3) + 5(-1),\ -(3) -4(-1)] &=\\
        (3,\ -1,\ 12 - 5,\ -3 +4) &=\\
        (3,\ -1,\ 7,\ 1).
      \end{align*}

      So, $(3,-1,0,-1)$ is not in the subspace, although $(3,-1,7,1)$ is.

    \item
      If $W$ is the set of all $(x_1,x_2,x_3,x_4,x_5)$ in $R^5$ which satisfy
      \begin{alignat*}{12}
        2x_1&\ -\ &  x_2\ & +\ & \frac{4}{3}x_3\ & -\ &  x_4\ &  \ &     \ & =\ & 0&\\
         x_1&   \ &     \ & +\ & \frac{2}{3}x_3\ &  \ &     \ & -\ &  x_5\ & =\ & 0&\\
        9x_1&\ -\ & 3x_2\ & +\ &           6x_3\ & -\ & 3x_4\ & -\ & 3x_5\ & =\ & 0&,
      \end{alignat*}
      we would like to find a finite set of vectors $S$ which spans $W$.

      In other words, we would like to find a finite set of vectors $S$ such that $W$ is
      the intersection of all the subspaces of $R^5$ that contain $S$. Another way of
      putting this is that $S$ should be such that $W$ is the smallest subspace of
      $R^5$ which contains $S$.

      Further, we know by theorem 3 that $S$ should be such that $W$ is the set of
      all linear combinations of $S$. Let $A$ be the matrix of coefficients of the
      system which defines $W$, i.e.
      \begin{align*}
        A =
        \begin{bmatrix}
          2 & -1 & \frac{4}{3} &  -1 &  0 \\
          1 &  0 & \frac{2}{3} &   0 & -1 \\
          9 & -3 &           6 &  -3 & -3.
        \end{bmatrix}
      \end{align*}
      By theorem 2 of \say{Matrices,} we know that if a matrix $B$ is row-equivalent to
      $A$, then $AX = 0$ and $BX = 0$ have the same solutions, i.e. they define the
      same set of vectors in $R^5$. Since $A$ is row-equivalent to a row-reduced
      echelon matrix by theorem 5 of \say{Matrices,} we can find $S$ more easily by
      row-reducing $A$.

      \begin{align*}
        \begin{bmatrix}
          2 & -1 & \frac{4}{3} & -1 & 0\\
          1 & 0 & \frac{2}{3} & 0 & -1\\
          9 & -3 & 6 & -3 & -3
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          1 & 0 & \frac{2}{3} & 0 & -1\\
          2 & -1 & \frac{4}{3} & -1 & 0\\
          9 & -3 & 6 & -3 & -3
        \end{bmatrix}
      \end{align*}
      \begin{align*}
        \begin{bmatrix}
          1 & 0 & \frac{2}{3} & 0 & -1\\
          0 & -1 & 0 & -1 & 2\\
          9 & -3 & 6 & -3 & -3
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          1 & 0 & \frac{2}{3} & 0 & -1\\
          0 & -1 & 0 & -1 & 2\\
          0 & -3 & 0 & -3 & 6
        \end{bmatrix}
      \end{align*}
      \begin{align*}
        \begin{bmatrix}
          1 & 0 & \frac{2}{3} & 0 & -1\\
          0 & 1 & 0 & 1 & -2\\
          0 & -3 & 0 & -3 & 6
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          1 & 0 & \frac{2}{3} & 0 & -1\\
          0 & 1 & 0 & 1 & -2\\
          0 & 0 & 0 & 0 & 0
        \end{bmatrix}.
      \end{align*}

      So, $W$ is also the set of all $(x_1,x_2,x_3,x_4,x_5)$ in $R^5$ which satisfy
      \begin{alignat*}{12}
         x_1&   \ &     \ & +\ & \frac{2}{3}x_3\ &  \ &     \ & -\ &  x_5\ & =\ & 0&\\
            &   \ &  x_2\ &  \ &               \ & +\ &  x_4\ & -\ & 2x_5\ & =\ & 0&,
      \end{alignat*}
      or in other words,
      \begin{align*}
        x_1 =& -\frac{2}{3}x_3 + x_5\\
        x_2 =& -x_4 + 2x_5.
      \end{align*}
      Even more concisely, $W$ is the set of all vectors in $R^5$ with the structure
      $(-\frac{2}{3}x_3 + x_5,\ -x_4 + 2x_5,\ x_3,\ x_4,\ x_5)$. Then a finite set of
      vectors which spans $W$ is
      \begin{alignat*}{9}
        \alpha_1 =&\ (&\ -\frac{2}{3},&\ \ \ \ \ 0,&\ 1,&\ 0,&\ 0&\ )&,\\
        \alpha_2 =&\ (&\            0,&\ -1,&\ 0,&\ 1,&\ 0&\ )&,\\
        \alpha_3 =&\ (&\            1,&\ \ \ \ \ 2,&\ 0,&\ 0,&\ 1&\ )&.
      \end{alignat*}

      For proof, let $S$ be this set, i.e. $S = \{ \alpha_1, \alpha_2, \alpha_3 \}$.
      Let $C$ be a linear combination of $S$; then $C = c_1\alpha_1 + c_2\alpha_2 +
      c_3\alpha_3 = (-\frac{2}{3}c_1 + c_3,\ -c_2 + 2c_3,\ c_1,\ c_2,\ c_3)$. Thus
      the set of all $C$ is $W$, so $S$ spans $W$.

      As an addendum,
      \begin{align*}
        2x_1 - x_2 + \frac{4}{3}x_3 - x_4 =&\\
        2(-\frac{2}{3}c_1 + c_3) - (-c_2 + 2c_3) + \frac{4}{3}c_1 - c_2 =&\\
        -\frac{4}{3}c_1 + 2c_3 + c_2 - 2c_3 + \frac{4}{3}c_1 - c_2 =&\\
        (\frac{4}{3}c_1 - \frac{4}{3}c_1) + (2c_3 - 2c_3) + (c_2 - c_2) =&\\
        0.\ \ \ &\\\\
        x_1 + \frac{2}{3}x_3 - x_5 =&\\
        (-\frac{2}{3}c_1 + c_3) + \frac{2}{3}c_1 - c_3 =&\\
        (\frac{2}{3}c_1 - \frac{2}{3}c_1) + (c_3 - c_3) =&\\
        0.\ \ \ &\\\\
        9x_1 - 3x_2 + 6x_3 - 3x_4 - 3x_5 =&\\
        9(-\frac{2}{3}c_1 + c_3) - 3(-c_2 + 2c_3) + 6c_1 - 3c_2 - 3c_3 =&\\
        -6c_1 + 9c_3 + 3c_2 - 6c_3 + 6c_1 - 3c_2 - 3c_3 =&\\
        (6c_1 - 6c_1) + (3c_2 - 3c_2) + (9c_3 - 6c_3 - 3c_3) =&\\
        (6c_1 - 6c_1) + (3c_2 - 3c_2) + (9c_3 - 9c_3) =&\\
        0.\ \ \ &
      \end{align*}

    \item
      If $F$ is a field, $n$ is a positive integer $(n \geq 2)$, and $V$ is then the
      vector space of all $n \times n$ matrices over $F$, we would like to determine
      which of the following sets of matrices $A$ in $V$ are subspaces of $V$.
      \begin{enumerate}
        \item
          \textbf{All invertible $A$.} The set of all invertible $A$ is not a
          subspace of $V$, because the sum of two invertible matrices is not
          necessarily invertible. We proceed by contradiction. Assume that, for any
          invertible $n \times n$ matrices $A$ and $B$, $A + B$ is invertible. By
          theorem 12, an invertible $n \times n$ matrix is row-equivalent to the $n
          \times n$ identity matrix. Consider $I$ and $-I$; $I$ is plainly
          row-equivalent to itself, and $-I$ is row-equivalent to $I$ by repeated
          application of elementary row operation 1 to each of its rows using the
          scalar $-1$. Therefore, both $I$ and $-I$ are invertible. Another way of
          putting this is that $II = I$, and $-I(-I) = I$, so both $I$ and $-I$ are
          their own inverses respectively.

          However, $I - I = 0$. There is no matrix $N$ in $V$ such that $N0 = I$,
          because $N0 = 0$ for all $N$. Therefore $I - I = 0$ is not invertible,
          which contradicts our initial assumption. So, even if both $cA$ and $B$ are
          invertible, the sum $cA + B$ may not be, i.e. in the case where $c = -1$
          and $A,B = I$. Thus the set of all invertible $A$ in $V$ is not a subspace
          of $V$.

        \item
          \textbf{All non-invertible $A$.} The set of all non-invertible $A$ is not a
          subspace of $V$ either, for similar reasons to the set of invertible $A$.
          Again, we proceed by contradiction. Assume that for any non-invertible
          $A,B$ in $V$, $A + B$ is non-invertible. Take the case where $n = 2$, and
          let
          \begin{align*}
            A =
            \begin{bmatrix}
              1 & 0\\
              0 & 0
            \end{bmatrix},\
            B =
            \begin{bmatrix}
              0 & 0\\
              0 & 1
            \end{bmatrix}.
          \end{align*}
          Neither $A$ nor $B$ is invertible, as there is no series of elementary row
          operations that will map $A_{22}$ or $B_{11}$ to $1$. Multiplication of row
          $A_{2}$ or $B_{1}$ by a non-zero scalar will have no effect as those rows
          are all-zero, and adding row $A_{1}$ or $B_{2}$ multiplied by a non-zero
          scalar to their respective other rows will not change the value of $A_{22}$
          or $B_{11}$, nor will swapping rows in either.

          However, $A + B = I$, and $I$ is invertible as we touched on in the first
          problem. This condradicts our initial assumption, and thus even if $cA$ and
          $B$ are non-invertible, $cA + B$ may be, i.e. if $A,B$ are as defined above
          and $c = 1$. Therefore the set of all non-invertible matrices in $V$ is not
          a subspace of $V$.

        \item
          \textbf{All $A$ such that $AB = BA$, where $B$ is some fixed matrix in
          $V$.} Let $A,C$ be matrices in $V$ such that $AB = BA$ and $CB = BC$ for
          some fixed matrix $B$ in $V$. What we would like to determine is whether
          $(cA + C)B = B(cA + C)$ for any scalar $c$ in $F$. By our lemma in
          \say{Vector spaces,} $(cA + C)B = cAB + CB$ and $B(cA + C) = cBA + BC$. If
          $AB = BA$, then $cAB = cBA$, and since $CB = BC$, $cAB + CB = cBA + CB =
          cAB + BC = cBA + BC$. Therefore $(cA + C)B = B(cA + C)$, so the set of all
          $A$ in $V$ such that $AB = BA$ for some fixed matrix $B$ in $V$ is a subset
          of $V$.

        \item
          \textbf{All $A$ such that $A^2 = A$.} If $A,B$ are matrices in $V$ such
          that $A^2 = A$ and $B^2 = B$, what we would like to determine is whether
          $cA + B = (cA + B)^2$ for any scalar $c$ in $F$.
          \begin{align*}
            [(cA + B)^2]_{ij}
            &= \sum_{r = 1}^{n}(cA + B)_{ir}(cA + B)_{rj}\\
            &= \sum_{r = 1}^{n}(cA_{ir} + B_{ir})(cA_{rj} + B_{rj})\\
            &= \sum_{r = 1}^{n}(c^2A_{ir}A_{rj}
              + cB_{ir}A_{rj} + cA_{ir}B_{rj} + B_{ir}B_{rj})\\
            &= \sum_{r = 1}^{n}c^2A_{ir}A_{rj} +
              \sum_{r = 1}^{n} cB_{ir}A_{rj} +
              \sum_{r = 1}^{n} cA_{ir}B_{rj} +
              \sum_{r = 1}^{n} B_{ir}B_{rj}\\
            &= c^2\sum_{r = 1}^{n}A_{ir}A_{rj} +
              c\sum_{r = 1}^{n} B_{ir}A_{rj} +
              c\sum_{r = 1}^{n} A_{ir}B_{rj} +
              \sum_{r = 1}^{n} B_{ir}B_{rj}\\
            &= (c^2A^2 + cBA + cAB + B^2)_{ij}.
          \end{align*}
          Since $A^2 = A$ and $B^2 = B$ in this case, $(cA + B)^2 = c^2A + cBA + cAB
          + B$. This is not necessarily equal to $cA + B$. For instance, $I^2 = I$,
          so if $A,B = I$ and $c = 2$, $(cA + B)^2 = 4I + 2I + 2I + I = 9I$. However
          $2I + I = 3I$, so $cA + B \neq (cA + B)^2$ in this case. Thus the set of
          all $A$ in $V$ such that $A^2 = A$ is not a subspace of $V$.
        \end{enumerate}

        \item
          \begin{enumerate}
            \item
              We would like to prove that the only subspaces of $R^1$ are $R^1$ and
              the zero subspace. We know from the definition of a subspace that $R^1$
              and the zero subspace are subspaces of $R^1$. Now, since $R^1$ is over
              $\mathbb{R}$, if $c$ is any real number and $A \neq 0$ is a vector in
              $R^1$, $cA$ can be made to take on any value in $R^1$, because if $A =
              (\alpha_1),\ \alpha_1 \in \mathbb{R}$, $cA = c\alpha_1$. Therefore
              aside from the zero subspace there is no way to define a subset of
              $R^1$ in which, for $A,B$ in the subset, $cA + B$ cannot be made to
              take on any value in $R^1$ if $A \neq 0$.
            \item
              We would like to prove that a subspace of $R^2$ is either $R^2$, the
              zero subspace, or a space of all scalar muiltiples of some fixed vector
              in $R^2$ (a straight line through the origin in geometric terms). We
              have that $R^2$ and the zero subspace are subspaces of $R^2$ by
              definition. Otherwise, let $A = (\alpha_1,\alpha_2)$ be a vector in
              $R^2$. A scalar multiple of $A$ would be $cA = (c\alpha_1,c\alpha_2),\
              c \in \mathbb{R}$.  If $B = (d\alpha_1,d\alpha_2),\ B \in R^2,\ d \in
              \mathbb{R}$, then $cA + B = (c\alpha_1+d\alpha_1,\ c\alpha_2+d\alpha_2)
              = [(c+d)\alpha_1,\ (c+d)\alpha_2]$. Therefore the space of all scalar
              multiples of some fixed vector $A$ in $R^2$ is indeed a subspace of
              $R^2$. Otherwise, let $C = (\gamma_1,\gamma_2),\ C \in R^2,\ C \neq cA$
              for any $c \neq 0,\ c \in \mathbb{R}$. Then $cA + C$ can be any vector
              in $R^2$ by the choice of $C$, including multiplies of $A$; $C = (0,0)$
              must be permitted or $cA + C$ could not define a subspace by
              definition. Therefore the only subspaces in $R^2$ are those described.
            \item
              We would like to attempt to describe the subspaces of $R^3$. We know
              that $R^3$ itself and the zero subspace are two of them. The spaces of
              all scalar multiples of some fixed vector in $R^3$ are likely
              candidates as well (still a straight line through the origin in
              geometric terms). Let $A = (\alpha_1,\alpha_2,\alpha_3),\ B =
              (d\alpha_1,d\alpha_2,d\alpha_3),\ A,B \in R^3$. Then $cA + B =
              (c\alpha_1+d\alpha_1,c\alpha_2+d\alpha_2,c\alpha_3+d\alpha_3) =
              [(c+d)\alpha_1,(c+d)\alpha_2,(c+d)\alpha_3]$, so the spaces of all
              scalar multiples of some fixed vector in $R^3$ are indeed subspaces of
              $R^3$ as well.

              The space spanned by two vectors $A,B$ in $R^3$ such that $A,B \neq 0$
              and $cA \neq B$ for any scalar $c \in \mathbb{R}$ is also a subspace of
              $R^3$; $e(cA + dB) + (fA + gB) = ecA + edB + fA + gB = (ec + f)A + (ed
              + g)B$.  Although this pattern of proof would work for any number of
              vectors in $R^3$, the set of sums of three or more vectors that all fit
              these criteria is equivalent to $R^3$ as a whole, whereas with only two
              vectors a distinct subspace is defined. Consider:

              \begin{align*}
                \begin{bmatrix}
                  c\alpha_1 & c\alpha_2 & c\alpha_3\\
                  d\beta_1 & d\beta_2 & d\beta_3
                \end{bmatrix}
                \xrightarrow{}
                \begin{bmatrix}
                  1 & \frac{\alpha_2}{\alpha_1} & \frac{\alpha_3}{\alpha_1}\\
                  d\beta_1 & d\beta_2 & d\beta_3
                \end{bmatrix}
                \xrightarrow{}
              \end{align*}
              \begin{align*}
                \begin{bmatrix}
                  1 & \frac{\alpha_2}{\alpha_1} & \frac{\alpha_3}{\alpha_1}\\
                  \beta_1 & \beta_2 & \beta_3
                \end{bmatrix}
                \xrightarrow{}
                \begin{bmatrix}
                  1 & \frac{\alpha_2}{\alpha_1} & \frac{\alpha_3}{\alpha_1}\\
                  0 & \frac{\beta_2\alpha_1 - \beta_1\alpha_2}{\alpha_1} & \frac{\beta_3\alpha_1 -\beta_1\alpha_3}{\alpha_1}
                \end{bmatrix}
                \xrightarrow{}
              \end{align*}
              \begin{align*}
                \begin{bmatrix}
                  1 & \frac{\alpha_2}{\alpha_1} & \frac{\alpha_3}{\alpha_1}\\
                  0 & 1 & \frac{\beta_3\alpha_1 -\beta_1\alpha_3}{\beta_2\alpha_1 - \beta_1\alpha_2}
                \end{bmatrix}
                \xrightarrow{}
                \begin{bmatrix}
                  1 & 0 & \frac{\beta_2\alpha_3-\beta_3\alpha_2}
                               {\beta_2\alpha_1-\beta_1\alpha_2}\\
                  0 & 1 & \frac{\beta_3\alpha_1 -\beta_1\alpha_3}
                               {\beta_2\alpha_1 - \beta_1\alpha_2}
                \end{bmatrix}.
              \end{align*}

              This assumes that $\alpha_1 \neq 0$. Also, if $\beta_2 = 0$, it assumes
              that $\beta_1,\alpha_2 \neq 0$. In other words, the two possibilities
              with the maximum number of zeroes are:
              \begin{alignat*}{11}
                A &=&\ (&\alpha_1&,\ &        0&,\ & 0&)&\\
                B &=&\ (&       0&,\ &  \beta_2&,\ & 0&)&
                \shortintertext{and}
                A &=&\ (&\alpha_1&,\ & \alpha_2&,\ & 0&)&\\
                B &=&\ (& \beta_1&,\ &        0&,\ & 0&)&.
              \end{alignat*}
              This is consistent with the requirement that $A,B \neq 0$ and $cA \neq
              B$. In the second case, if $\alpha_2 = 0$, then $\beta_1 = x\alpha_1$
              for some scalar $x \in \mathbb{R}$, so then $B = xA$. If $\alpha_1 =
              0$, this is equivalent to the first case, as we can see by then
              switching the roles of $A$ and $B$. Also, if we have a situation in
              practice like
              \begin{alignat*}{11}
                A &=&\ (&0&,\ \alpha_2&,\ & \alpha_3&)&\\
                B &=&\ (&0&,\  \beta_2&,\ &        0&)&
              \end{alignat*}
              we can "change perspective" and call $\alpha_2,\beta_2$ as
              $\alpha_1,\beta_1$ and $\alpha_3$ as $\alpha_2$, or similar.

              The important thing is this: we can see from the row-reduction process
              above that any vector in this subspace is defined by only \textit{two}
              real numbers, say $x_1,x_2$, with the third real number in the vector
              being equal to
              \begin{align*}
                \frac{(\beta_2\alpha_3-\beta_3\alpha_2)x_1
                      + (\beta_3\alpha_1 -\beta_1\alpha_3)x_2}
                     {\beta_2\alpha_1-\beta_1\alpha_2}.
              \end{align*}
              This is in contrast to the space of $R^3$ as a whole in which all three
              real numbers are free, and therefore the subspace spanned by two
              vectors that fulfill our criteria is distinct from it.

              However, if we consider the subspace spanned by three such vectors:

              \begin{align*}
                \begin{bmatrix}
                  1 & 0 & \frac{\beta_2\alpha_3-\beta_3\alpha_2}
                               {\beta_2\alpha_1-\beta_1\alpha_2}\\
                  0 & 1 & \frac{\beta_3\alpha_1 -\beta_1\alpha_3}
                               {\beta_2\alpha_1 - \beta_1\alpha_2}\\
                  e\gamma_1 & e\gamma_2 & e\gamma_3
                \end{bmatrix}
                \xrightarrow{}
                \begin{bmatrix}
                  1 & 0 & \frac{\beta_2\alpha_3-\beta_3\alpha_2}
                               {\beta_2\alpha_1-\beta_1\alpha_2}\\
                  0 & 1 & \frac{\beta_3\alpha_1 -\beta_1\alpha_3}
                               {\beta_2\alpha_1 - \beta_1\alpha_2}\\
                  \gamma_1 & \gamma_2 & \gamma_3
                \end{bmatrix}
                \xrightarrow{}
              \end{align*}
              \begin{align*}
                \begin{bmatrix}
                  1 & 0 & \frac{\beta_2\alpha_3-\beta_3\alpha_2}
                               {\beta_2\alpha_1-\beta_1\alpha_2}\\
                  0 & 1 & \frac{\beta_3\alpha_1 -\beta_1\alpha_3}
                               {\beta_2\alpha_1 - \beta_1\alpha_2}\\
                  0 & \gamma_2 & \gamma_3
                            - \frac{\beta_2\alpha_3-\beta_3\alpha_2}
                                   {\beta_2\alpha_1-\beta_1\alpha_2}\gamma_1
                \end{bmatrix}
                \xrightarrow{}
                \begin{bmatrix}
                  1 & 0 & \frac{\beta_2\alpha_3-\beta_3\alpha_2}
                               {\beta_2\alpha_1-\beta_1\alpha_2}\\
                  0 & 1 & \frac{\beta_3\alpha_1 -\beta_1\alpha_3}
                               {\beta_2\alpha_1 - \beta_1\alpha_2}\\
                  0 & 0 & \gamma_3
                          - \frac{(\beta_2\alpha_3-\beta_3\alpha_2)\gamma_1 +
                                  (\beta_3\alpha_1 -\beta_1\alpha_3)\gamma_2}
                                 {\beta_2\alpha_1-\beta_1\alpha_2}
                \end{bmatrix}
                \xrightarrow{}
              \end{align*}
              \begin{align*}
                \begin{bmatrix}
                  1 & 0 & \frac{\beta_2\alpha_3-\beta_3\alpha_2}
                               {\beta_2\alpha_1-\beta_1\alpha_2}\\
                  0 & 1 & \frac{\beta_3\alpha_1 -\beta_1\alpha_3}
                               {\beta_2\alpha_1 - \beta_1\alpha_2}\\
                  0 & 0 & 1
                \end{bmatrix}
                \xrightarrow{}
                \begin{bmatrix}
                  1 & 0 & \frac{\beta_2\alpha_3-\beta_3\alpha_2}
                               {\beta_2\alpha_1-\beta_1\alpha_2}\\
                  0 & 1 & 0\\
                  0 & 0 & 1
                \end{bmatrix}
                \xrightarrow{}
              \end{align*}
              \begin{align*}
                \begin{bmatrix}
                  1 & 0 & 0\\
                  0 & 1 & 0\\
                  0 & 0 & 1
                \end{bmatrix},
              \end{align*}

              we can see that it is equivalent to $R^3$ as a whole, provided that the
              third vector is outside the subspace spanned by the first two. (If we call the
              third vector $C = (\gamma_1,\gamma_2,\gamma_3)$, we can see that $C$
              must be such that $\gamma_3 \neq
              \frac{(\beta_2\alpha_3-\beta_3\alpha_2)\gamma_1 + (\beta_3\alpha_1
              -\beta_1\alpha_3)\gamma_2} {\beta_2\alpha_1-\beta_1\alpha_2}$ provided
              $A$ and $B$ are as before, which is equivalent to saying that it must
              be outside the subspace spanned by $A$ and $B$ alone.)

              Therefore the subspaces of $R^3$ are the zero subspace, the subspace
              spanned by one non-$0$ vector in $R^3$, the subspace spanned by two
              vectors in $R^3$ that are not linear combinations of each other, and
              $R^3$ as a whole.
          \end{enumerate}

    \item
      If $W_1$ and $W_2$ are subspaces of a vector space $V$ over a field $F$ such
      that $W_1 \cup W_2$ is also a subspace, we would like to prove that one of the
      subspaces $W_i$ is contained in the other.

      We proceed by contradiction. Let $W_1 \cup W_2$ be a subspace, and let $X_1
      \subset W_1$ and $X_2 \subset W_2$ be non-empty sets such that $X_1,X_2
      \not\subset W_1 \cap W_2$. By theorem 2, $W_1 \cap W_2$ is a subspace. Because
      $W_1 \cup W_2$ is a subspace, $c\alpha_1 + d\alpha_2$ where $\alpha_1 \in X_1,\
      \alpha_2 \in X_2,\ c,d \in F$ must be in $W_1 \cup W_2$. However, we know that
      $X_1$ and $X_2$ have no elements in common by definition, and by theorem 1 we
      know that if a vector $\gamma$ is not in $W_1$, then for a vector $\delta$ in
      $W_1$, $c\gamma + \delta$ must not be in $W_1$ for at least some values of $c$
      and $\delta$; likewise for $W_2$. Therefore $c\alpha_1 + d\alpha_2$ must not be
      in $W_1$ or $W_2$ for at least some values of $c,d,\alpha_1,\alpha_2$. This
      contradicts the notion that $W_1 \cup W_2$ is a subspace, as it contains $X_1$
      and $X_2$ together.

      Therefore if $X_1$ and $X_2$ really are both not included in $W_1 \cap W_2$,
      $W_1 \cup W_2$ is not a subspace. If $W_1 \cup W_2$ is a subspace, then at
      least one of $X_1$ and $X_2$ must be included in $W_1 \cap W_2$. In other
      words, at least one of $W_1$ and $W_2$ must be included in $W_1 \cap W_2$ in
      its entirety, so that $W_1 \cap W_2$ and $W_1 \cup W_2$ are the same set. This
      implies that at least one of $W_1$ and $W_2$ has no elements that are not
      present in the other, i.e. that it is contained in the other.

    \item
      If $V$ is the vector space of all functions from $R$ into $R$, $V_e$ is the
      subset of even functions ($f(-x) = f(x)$), and $V_o$ is the subset of odd
      functions ($f(-x) = -f(x)$), we would like to prove the following statements.
      In the proofs that follow, let $g_e$ and $h_e$ be even functions, and let $g_o$
      and $h_o$ be odd functions.
      \begin{enumerate}
        \item
          \textbf{$V_e$ and $V_o$ are subspaces of $V$.}
          \begin{align*}
            (cg_e + h_e)(-x) &=
            (cg_e)(-x) + h_e(-x)\\
            &= cg_e(-x) + h_e(-x)\\
            &= cg_e(x) + h_e(x)\\
            &= (cg_e)(x) + h_e(x)\\
            &= (cg_e + h_e)(x)
            \shortintertext{and}
            (cg_o + h_o)(-x) &=
            (cg_o)(-x) + h_o(-x)\\
            &= cg_o(-x) + h_o(-x)\\
            &= c(-g_o)(x) + (-h_o)(x)\\
            &= (-cg_o)(x) + (-h_o)(x)\\
            &= (-cg_o - h_o)(x)\\
            &= -(cg_o + h_o)(x).
          \end{align*}

        \item
          \textbf{$V_e + V_o = V$.} The vector space $V_e + V_o$ contains all the
          linear combinations of the elements of $V_e$ and $V_o$. If we consider some
          $x \in \mathbb{R}$ and a function $f: \mathbb{R} \to \mathbb{R}$, then
          $f(x) = y$ for some $y \in \mathbb{R}$. If $f$ is even, we can obtain $f$
          through the sum of some set of even functions $f_{e_1},\cdots,f_{e_n}$ such
          that there is some $f_{e_i},\ 1 \leq i \leq n$ where $f(x) = f_{e_i}(x)$
          for any $x \in \mathbb{R}$, since the sum of even functions is even. The
          same is true if $f$ is odd regarding some set of odd functions
          $f_{o_1},\cdots,f_{o_n}$, since the sum of odd functions is odd. Both of
          these statements follow from $V_e$ and $V_o$ being vector spaces.

          Now consider a function $f: \mathbb{R} \to \mathbb{R}$ that is the sum of
          an even and an odd function, i.e.
          \begin{align*}
            f(-x) &= (g_e + g_o)(-x).
            \shortintertext{Then}
            f(-x) &= g_e(-x) + g_o(-x)\\
            &= g_e(x) - g_o(x),\\
            \shortintertext{so}
            f(-x) + g_o(x) &= g_e(x)
            \shortintertext{and}
            f(-x) - g_e(x) &= - g_o(x);\\
            -f(-x) + g_e(x) &= g_o(x).
            \shortintertext{Then}
            f(-x) &= f(-x) + g_o(x) - [-f_x(-x) + g_e(x)]\\
            &= f(-x) + g_o(x) + f_x(-x) - g_e(x)\\
            &= [f(-x) + f_x(-x)] + g_o(x) - g_e(x)\\
            &= 2f(-x) + g_o(x) - g_e(x),
            \shortintertext{so}
            -f(-x) &= g_o(x) - g_e(x);\\
            f(-x) &= g_e(x) - g_o(x)\\
            &= (g_e - g_o)(x).
          \end{align*}
          Thus $(g_e + g_o)(-x) = (g_e - g_o)(x)$, and so if $f(x) = (g_e + g_o)(x)$
          then $f(x) = (g_e - g_o)(-x)$.

          Now consider a function $f: \mathbb{R} \to \mathbb{R}$ that is neither even
          nor odd. For $x \in \mathbb{R},\ x \geq 0$, we know that there is an even
          function $g_e$ and an odd function $g_o$ such that $f(x) = (g_e + g_o)(x)$,
          since any real number can be expressed as the sum of two others and any
          even or odd function can be expressed as the sum of some (potentially
          infinite) number of even or odd functions respectively. Then $f(-x) = (g_e
          + g_o)(-x) = g_e(-x) + g_o(-x) = g_e(x) - g_o(x)$. If $g_o(x)$ is positive,
          then $g_o(-x) = -g_o(x)$ is negative, so $g_e(x) + g_o(x) \neq g_e(x) -
          g_o(x)$ unless $g_o(x) = 0$, and $g_e(x) + g_o(x) \neq -(g_e + g_o)(x) =
          -g_e(x) - g_o(x)$ unless both $g_e(x)$ and $g_o(x)$ are $0$. Therefore if
          $f(x) \neq 0$, it is possible to have $f(x) \neq f(-x) \neq -f(x)$, so
          $f(x) = (g_e + g_o)(x)$ is consistent with $f$ being neither even nor odd,
          and thus there is some $g_e$ and $g_o$ the sum of which will cover the
          whole range of $f$.

          Therefore $V_e + V_o$ contains every function from $\mathbb{R}$ into
          $\mathbb{R}$ that is odd, even, or neither, and thus $V_e + V_o = V$.

        \item
          \textbf{$V_e \cap V_o = \{0\}$.} $g_e(x) = g_e(-x)$, but $g_o(x) =
          -g_o(-x) \neq g_o(-x)$ unless $g_o(x) = g_o(-x) = 0$. Therefore the only
          function that is in both $V_e$ and $V_o$ is the function $f_0: \mathbb{R}
          \to \mathbb{R}$ such that $f_0(x) = 0$.
      \end{enumerate}

  \end{enumerate}
\end{document}
