\documentclass[12pt]{article}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{fontspec}
\usepackage{xfrac}
\usepackage{array}
\usepackage{siunitx}
\usepackage{gensymb}
\usepackage{enumitem}
\usepackage{dirtytalk}
\usepackage{bm}
\title{Vector spaces}
\author{ZoÃ« Sparks}

\begin{document}

\theoremstyle{definition}

\sisetup{quotient-mode=fraction}
\newtheorem{thm}{Theorem}
\newtheorem*{nthm}{Theorem}
\newtheorem{sthm}{}[thm]
\newtheorem{lemma}{Lemma}[thm]
\newtheorem*{nlemma}{Lemma}
\newtheorem{cor}{Corollary}[thm]
\newtheorem*{prop}{Property}
\newtheorem*{defn}{Definition}
\newtheorem*{comm}{Comment}
\newtheorem*{exm}{Example}

\maketitle

\begin{defn}
  A \textbf{vector space}, also known as a linear space, consists
  of:
  \begin{enumerate}
    \item
      a field $F$ of scalars;
    \item
      a set $V$ of objects called \textbf{vectors};
    \item
      a rule or operation called \textbf{vector addition},
      which associates each pair of vectors $\alpha,\ \beta$ in
      $V$ with a vector $\alpha + \beta$ in $V$, called the sum
      of $\alpha$ and $\beta$, and which fulfills the criteria
      that
      \begin{enumerate}
        \item
          vector addition is commutative: $\alpha + \beta = \beta
          + \alpha$;
        \item
          vector addition is associative: $\alpha + (\beta +
          \gamma) = (\alpha + \beta) + \gamma$;
        \item
          there is a unique vector $0$ in $V$ called the
          \textbf{zero vector} and which is the additive identity
          for vector addition, i.e. $\alpha + 0 = \alpha$ for all
          $\alpha$ in $V$;
        \item
          for each vector $\alpha$ in $V$ there is a unique
          vector $-\alpha$ in $V$ which is the additive inverse
          of $\alpha$, i.e. $\alpha + (-\alpha) = 0$;
      \end{enumerate}
    \item
      a rule or operation called \textbf{scalar multiplication},
      which associates each scalar $c$ in $F$ and vector $\alpha$
      in $V$ with a vector $c\alpha$ in $V$, called the product
      of $c$ and $\alpha$, and which fulfills the criteria that
      \begin{enumerate}
        \item
          $c(\alpha + \beta) = c\alpha + c\beta$;
        \item
           $(c_1 +c_2)\alpha = c_1\alpha + c_2\alpha$;
        \item
          $(c_1c_2)\alpha = c_1(c_2\alpha)$;
        \item
          $1\alpha = \alpha$ for every $\alpha$ in $V$.
      \end{enumerate}
  \end{enumerate}
  Sometimes we will refer to a vector space simply as $V$ if
  there is no chance of confusion about the specific vector space
  under discussion. In some cases, we will need to specify the
  field, in which case we will say that $V$ is a \textbf{vector
  space over the field} $F$.
\end{defn}

\begin{comm}
  It's important to note that a vector space is a
  \textit{composite} object, consisting of a field $F$, a set $V$
  of some kind of objects called \say{vectors,} and two
  operations with certain properties. You may have certain
  preconceived ideas about what constitutes a vector, but it's
  worth putting those aside to an extent if so, as the vectors of
  a given vector space may be quite different from what you
  currently imagine. In particular, the elements of $V$ need have
  no intrinsic relationship to $F$ aside from what's needed to
  define vector addition and scalar multiplication between them.
\end{comm}

\begin{exm}
  \textbf{The \textit{n}-tuple space}, $F^n$. Let $F$ be any
  field, and let $V$ be the set of all $n$-tuples $\alpha =
  (x_1,x_2,\ldots,x_n)$ of scalars $x_i$ in $F$. If $\beta =
  (y_1,y_2,\ldots,y_n)$ with $y_i$ in $F$, the sum of $\alpha$
  and $\beta$ is defined as
  \begin{align*}
    \alpha + \beta = (x_1 + y_1,x_2 + y_2,\ldots,x_n + y_n),
  \end{align*}
  and the product of a scalar $c$ and a vector $\alpha$ is
  defined by
  \begin{align*}
    c\alpha = (cx_1,cx_2,\ldots,cx_n).
  \end{align*}
\end{exm}

\begin{exm}
  \textbf{The space of} $m \times n$ \textbf{matrices}, $F^{m
  \times n}$. Let $F$ be any field and let $m$ and $n$ be
  positive integers. Let $F^{m \times n}$ be the set of all $m
  \times n$ matrices over $F$. The sum of two vectors $A$ and $B$
  in $F^{m \times n}$ is defined as
  \begin{align*}
    (A + B)_{ij} = A_{ij} + B_{ij},
  \end{align*}
  and the product of a scalar $c$ and the matrix $A$ is defined
  by
  \begin{align*}
    (cA)_{ij} = cA_{ij}.
  \end{align*}
  Notably, $F^{1 \times n} = F^n$.
\end{exm}

\begin{exm}
  \textbf{The space of functions from a set into a field.} Let
  $F$ be any field and let $S$ be any non-empty set. Let $V$ be
  the set of all functions from $S$ into $F$. Then the sum of two
  vectors $f$ and $g$ in $V$ is defined as
  \begin{align*}
    (f + g)(s) = f(s) + g(s).
  \end{align*}
  The product of the scalar $c$ and the function (vector) $f$ is
  the function $cf$, defined as
  \begin{align*}
    (cf)(s) = cf(s).
  \end{align*}
\end{exm}

\begin{comm}
  The two preceding examples are, in fact, special cases of this
  one. An $n$-tuple of elements of $F$ can be treated as a
  function from the set $S$ of integers $1,\ldots,n$ into $F$,
  just as we earlier defined an $m \times n$ matrix over $F$ as a
  function from the set $S$ of pairs of integers, $(i,j),\ 1 \leq
  i \leq m,\ 1 \leq j \leq n$, into $F$.
\end{comm}

\begin{exm}
  \textbf{The space of polynomial functions over a field $F$.}
  Let $F$ be a field and let $V$ be the set of all functions $f$
  from $F$ into $F$ which have a rule of the form
  \begin{align*}
    f(x) = c_0 + c_1x + \cdots + c_nx^n,
  \end{align*}
  where $c_0,c_1,\ldots,c_n$ are fixed scalars in $F$ with no
  dependence on $x$. This sort of function is called a
  \textbf{polynomial function on $F$}. Addition and scalar
  multiplication can be defined for this vector space in the same
  manner as the preceding example.
\end{exm}

\begin{exm}
  The field $\mathbb{C}$ of complex numbers can be treated as a
  vector space over the field $\mathbb{R}$ of real numbers. More
  generally, we can let $F$ be the field of \textit{real} numbers
  and $V$ be the set of $n$-tuples $\alpha = (x_1,\ldots,x_n)$
  where $x_1,\ldots,x_n$ are \textit{complex} numbers, defining
  vector addition and scalar multiplication as we did for the
  $n$-tuple space $F^n$, which yields a different sort of vector
  space than either $\mathbb{C}^n$ or $\mathbb{R}^n$.
\end{exm}

\begin{comm}
  If $c$ is a scalar and $0$ is the zero vector, then by 3(c) and
  4(a) we have that
  \begin{align*}
    c0 = c(0 + 0) = c0 + c0;
  \end{align*}
  then by 3(d) we have that
  \begin{align*}
    c0 + c0 - (c0) = c0 - (c0) = c0 = 0.
  \end{align*}
  Likewise, for the scalar $0$ and any vector $\alpha$, we have
  that
  \begin{align*}
    0\alpha = 0,
  \end{align*}
  in which the latter $0$ is the zero vector.

  If $c \neq 0$ is a scalar and $\alpha$ is a vector such that
  $c\alpha = 0$, we then have that $c^{-1}(c\alpha) = c^{-1}(0) =
  0$; this implies that
  \begin{align*}
    c^{-1}(c\alpha) = (c^{-1}c)\alpha = 1\alpha = \alpha = 0.
  \end{align*}

  So, if $c$ is a scalar and $\alpha$ is a vector such that
  $c\alpha = 0$, then either $c = 0$, $\alpha = 0$, or both.
\end{comm}

\begin{comm}
  If $\alpha$ is any vector,
  \begin{align*}
    0 = 0\alpha = (1 - 1)\alpha = 1\alpha + (-1)\alpha = \alpha +
    (-1)\alpha,
  \end{align*}
  and thus
  \begin{align*}
    (-1)\alpha = -\alpha.
  \end{align*}
\end{comm}

\begin{comm}
  Since vector addition is both associative and commutative, we
  have that if $\alpha_1,\alpha_2,\alpha_3,\alpha_4$ are vectors,
  then
  \begin{align*}
    (\alpha_1 + \alpha_2) + (\alpha_3 + \alpha_4) &=\\
    \alpha_4 + [\alpha_2 + (\alpha_1 + \alpha_3)] &=\\
    \alpha_1 + \alpha_2 + \alpha_3 + \alpha_4&
  \end{align*}
  and so on.
\end{comm}

\begin{defn}
  A vector $\beta$ in $V$ is called a \textbf{linear combination}
  of the vectors $\alpha_1,\ldots,\alpha_n$ in $V$ if there are
  scalars $c_1,\ldots,c_n$ in $F$ such that
  \begin{align*}
    \beta &= c_1\alpha_1 + \cdots + c_n\alpha_n\\
          &= \sum_{i = 1}^{n}c_i\alpha_i.
  \end{align*}
\end{defn}

\begin{comm}
  The associativity of vector addition and the distributivities
  4(a) and 4(b) of scalar multiplication imply that
  \begin{align*}
    \sum_{i = 1}^{n}c_i\alpha_i + \sum_{i = 1}^{n}d_i\alpha_i =
    \sum_{i = 1}^{n}(c_i + d_i)\alpha_i
  \end{align*}
  and that
  \begin{align*}
    c\sum_{i = 1}^{n}c_i\alpha_i = \sum_{i =
    1}^{n}(cc_i)\alpha_i.
  \end{align*}
\end{comm}

\begin{defn}
  If $V$ is a vector space over the field $F$, we say that a subset $W$ of $V$ is a
  \textbf{subspace} of $V$ if $W$ is itself a vector space over $F$ with the
  operations of vector addition and scalar multiplication on $V$.
\end{defn}

\begin{comm}
  By the axioms for a vector space, the subset $W$ of $V$ is a subspace if
  \begin{enumerate}
    \item
      for each $\alpha$ and $\beta$ in $W$, the vector $\alpha + \beta$ is in $W$,
    \item
      the $0$ vector is in $W$,
    \item
      for each $\alpha$ in $W$ the vector $(-\alpha)$ is in $W$, and
    \item
      for each $\alpha$ in $W$ and each scalar $c$ the vector $c\alpha$ is in $W$.
  \end{enumerate}
\end{comm}

\end{document}
