\documentclass[12pt]{article}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{fontspec}
\usepackage{xfrac}
\usepackage{array}
\usepackage{siunitx}
\usepackage{gensymb}
\usepackage{enumitem}
\title{Matrices}
\author{ZoÃ« Sparks}

\begin{document}

\theoremstyle{definition}

\sisetup{quotient-mode=fraction}
\newtheorem{thm}{Theorem}
\newtheorem*{nthm}{Theorem}
\newtheorem{sthm}{}[thm]
\newtheorem{lemma}{Lemma}[thm]
\newtheorem*{cor}{Corollary}
\newtheorem*{prop}{Property}
\newtheorem*{defn}{Definition}
\newtheorem*{comm}{Comment}
\newtheorem*{exm}{Example}

\maketitle

\begin{defn}
  We can abbreviate this system:
  \begin{equation} \label{eq:syslin}
  \begin{array}{ccccccccc}
    A_{11}x_1 & + & A_{12}x_2 & + & \ldots & + & A_{1n}x_n & = & y_1\\
    A_{21}x_1 & + & A_{22}x_2 & + & \ldots & + & A_{2n}x_n & = & y_2\\
    \vdots    & + & \vdots    & + & \ldots & + & \vdots    & = & \vdots\\
    A_{m1}x_1 & + & A_{m2}x_2 & + & \ldots & + & A_{mn}x_n & = & y_m
  \end{array}
  \end{equation}
  by
  \begin{align*}
    AX = Y
  \end{align*}
  where\\
  \[
    \begin{array}{cccll}
      &A =
      &\begin{bmatrix}
        A_{11} & \cdots & A_{1n}\\
        \vdots & \ddots & \vdots\\
        A_{m1} & \cdots & A_{mn}
      \end{bmatrix}&&\\\\
      X =&
      \begin{bmatrix}
        x_{1} \\
        \vdots\\
        x_{n}
      \end{bmatrix}&
      \text{ and }
      &Y =&
      \begin{bmatrix}
        y_{1} \\
        \vdots\\
        y_{m}
      \end{bmatrix}.
    \end{array}
  \]\\

  We call $A$ the \textbf{matrix of coefficients} of
  \eqref{eq:syslin}. To be strict, though, $A$ is not truly a
  matrix, but rather a representation of a matrix. We define an
  $m \times n$ \textbf{matrix over the field} $F$ to be a
  function $A$ from the set of pairs of integers $(i,j)$, $1 \leq
  i \leq m$, $1 \leq j \leq n$ into the field $F$. We call the
  scalars $A(i,j) = A_{ij}$ the \textbf{entries} of $A$. As
  above, it's often convenient to represent a matrix as a
  rectangular $m \times n$ array with the entries shown inside.
  $X$ above is, or defines, an $n \times 1$ matrix, and $Y$ above
  is an $m \times 1$ matrix.
\end{defn}

\begin{defn}
  An \textbf{elementary row operation} is one of the following
  three functions which associate with each $m \times n$ matrix
  $A$ an $m \times n$ matrix $e(A)$:
  \begin{enumerate}
      \item \label{ero1}
        multiplication of one row of $A$ by a non-zero scalar
        $c$:
        \begin{equation*}
          e(A)_{ij} = A_{ij} \text{ if } i \neq r,\text{ }e(A)_{rj} = cA_{rj};
        \end{equation*}
      \item \label{ero2}
        replacement of the $r$th row of $A$ by row $r$ plus $c$
        times row $s$, $c$ any scalar and $r \neq s$:
        \begin{equation*}
          e(A)_{ij} = A_{ij} \text{ if } i \neq r,\text{ }e(A)_{rj} =
          A_{rj} + cA_{sj};
        \end{equation*}
      \item \label{ero3}
        interchange of two rows of $A$:
        \begin{equation*}
          e(A)_{ij} = A_{ij} \text{ if } i \neq r \text{ and } i
          \neq s,\text{ }e(A)_{rj} = A_{sj},\text{ }e(A)_{sj} = A_{rj}.
        \end{equation*}
  \end{enumerate}

  In all of these operations, it doesn't matter much how many
  columns $A$ has, but it's clearly very important how many rows
  it has; for instance, a $1 \times n$ matrix doesn't have two
  row indices not equal to each other. For this reason, we define
  elementary row operations for $m \times n$ matrices over $F$
  for any $n$ but a fixed $m$.
\end{defn}

\begin{thm}
  To each elementary row operation $e$ there corresponds an
  elementary row operation $e_1$ of the same type as $e$ such
  that $e_1(e(A)) = e(e_1(A)) = A$ for each $A$. In other words,
  for each elementary row operation, the inverse function exists
  and is of the same type.
  \begin{proof}
    For \eqref{ero1}, if
      \begin{equation*}
        e(A)_{ij} = A_{ij} \text{ if } i \neq r,\text{ }e(A)_{rj}
        = cA_{rj},
      \end{equation*}
    then
      \begin{equation*}
        e_{1}(A)_{ij} = A_{ij} \text{ if } i \neq r,\text{ }e_{1}(A)_{rj}
        = c^{-1}A_{rj}.
      \end{equation*}
    Then $e_{1}(e(A))_{rj} = e(e_{1}(A))_{rj} = cc^{-1}A_{rj} =
    A_{rj}$, and otherwise $e_{1}(e(A))_{ij} = e(e_{1}(A))_{rj} =
    A_{ij}$.

    For \eqref{ero2}, if
      \begin{equation*}
        e(A)_{ij} = A_{ij} \text{ if } i \neq r,\text{ }e(A)_{rj} =
        A_{rj} + cA_{sj},
      \end{equation*}
    then
      \begin{equation*}
        e_{1}(A)_{ij} = A_{ij} \text{ if } i \neq r,\text{ }e_{1}(A)_{rj} =
        A_{rj} - cA_{sj}.
      \end{equation*}
    Then $e_{1}(e(A))_{rj} = e(e_{1}(A))_{rj} = A_{rj} + A_{sj} -
    A_{sj} = A_{rj}$, and otherwise $e_{1}(e(A))_{ij} =
    e(e_{1}(A))_{rj} = A_{ij}$.

    For \eqref{ero3}, if
      \begin{equation*}
        e(A)_{ij} = A_{ij} \text{ if } i \neq r \text{ and } i
        \neq s,\text{ }e(A)_{rj} = A_{sj},\text{ }e(A)_{sj} = A_{rj},
      \end{equation*}
    then $e = e_{1}$. $e(e(A)_{rj}) = e(A_{sj}) = A_{rj}$,
    $e(e(A)_{sj}) = e(A_{rj}) = A_{sj}$, and otherwise
    $e_{1}(e(A))_{ij} = e(e_{1}(A))_{rj} = A_{ij}$.
  \end{proof}
\end{thm}

\begin{defn}

\end{defn}

\end{document}
