\documentclass[12pt]{article}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{fontspec}
\usepackage{xfrac}
\usepackage{array}
\usepackage{siunitx}
\usepackage{gensymb}
\usepackage{enumitem}
\usepackage{dirtytalk}
\title{Matrices (exercises)}
\author{ZoÃ« Sparks}

\begin{document}

\theoremstyle{definition}

\sisetup{quotient-mode=fraction}
\newtheorem{thm}{Theorem}
\newtheorem*{nthm}{Theorem}
\newtheorem{sthm}{}[thm]
\newtheorem{lemma}{Lemma}[thm]
\newtheorem{cor}{Corollary}[thm]
\newtheorem*{prop}{Property}
\newtheorem*{defn}{Definition}
\newtheorem*{comm}{Comment}
\newtheorem*{exm}{Example}

\maketitle

\begin{enumerate}
    \item
      We have
      \begin{align*}
        (1 - i)x_1 - ix_2 = &\ 0\\
        2x_1 - (1 - i)x_2 = &\ 0.
      \end{align*}
      We would like to find the solutions. We can represent this
      system as
      \begin{align*}
        \begin{bmatrix}
          (1 - i) & -i \\
          2       & -(1 - i)
        \end{bmatrix}
        \begin{bmatrix}
          x_1 \\
          x_2
        \end{bmatrix}
        =
        \begin{bmatrix}
          0 \\
          0
        \end{bmatrix}.
      \end{align*}

      We row-reduce the first matrix.
      \begin{align*}
        \begin{bmatrix}
          (1 - i) & -i \\
          2       & -(1 - i)
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          (1 - i) & -i \\
          1       & -(\frac{1}{2} - \frac{1}{2}i)
        \end{bmatrix}
        \xrightarrow{}
      \end{align*}
      \begin{align*}
        \begin{bmatrix}
          (1 - i) - (1 - i) & -i -i \\
          1       & -(\frac{1}{2} - \frac{1}{2}i)
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          0 & -2i \\
          1 & -(\frac{1}{2} - \frac{1}{2}i)
        \end{bmatrix}
        \xrightarrow{}
      \end{align*}
      \begin{align*}
        \begin{bmatrix}
          0 & 1 \\
          1 & -(\frac{1}{2} - \frac{1}{2}i)
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          0 & 1 \\
          1 & 0
        \end{bmatrix}.
      \end{align*}
      So, this system has only the solution $x_1 = x_2 = 0$.

    \item
      We want to row-reduce
      \begin{align*}
        A\ & =
        \begin{bmatrix}
          3 & -1 & 2\\
          2 &  1 & 1\\
          1 & -3 & 0
        \end{bmatrix}.
      \end{align*}
      \begin{align*}
        \begin{bmatrix}
          1 & -\frac{1}{3} & \frac{2}{3}\\
          2 &  1 & 1\\
          1 & -3 & 0
        \end{bmatrix};\\\\
        \begin{bmatrix}
          1 & -\frac{1}{3}  & \frac{2}{3}\\
          0 &  1\frac{2}{3} & -\frac{1}{3}\\
          0 & -2\frac{2}{3} & -\frac{2}{3}
        \end{bmatrix};\\\\
        \begin{bmatrix}
          1 & -\frac{1}{3}  & \frac{2}{3}\\
          0 &  1            & -\frac{1}{5}\\
          0 & -2\frac{2}{3} & -\frac{2}{3}
        \end{bmatrix};\\\\
        \begin{bmatrix}
          1 & 0 & \frac{3}{5}\\
          0 & 1 & -\frac{1}{5}\\
          0 & 0 & -1\frac{1}{5}
        \end{bmatrix};\\\\
        \begin{bmatrix}
          1 & 0 & \frac{3}{5}\\
          0 & 1 & -\frac{1}{5}\\
          0 & 0 & 1
        \end{bmatrix};\\\\
        \begin{bmatrix}
          1 & 0 & 0\\
          0 & 1 & 0\\
          0 & 0 & 1
        \end{bmatrix}.
      \end{align*}
      So, the only solution of $AX = 0$ is $x_1 = x_2 = x_3 = 0$.

    \item
      For
      \begin{align*}
        A\ & =
        \begin{bmatrix}
          6 & -4 & 0\\
          4 &  2 & 0\\
         -1 &  0 & 3
        \end{bmatrix},
      \end{align*}
      we would like to find all solutions in which $AX = 2X$ and
      all solutions in which $AX = 3X$.

      First we have
      \begin{align*}
        \begin{bmatrix}
          6 & -4 & 0\\
          4 &  2 & 0\\
         -1 &  0 & 3
        \end{bmatrix}
        \begin{bmatrix}
          x_1 \\
          x_2 \\
          x_3
        \end{bmatrix}
        =
        \begin{bmatrix}
          2x_1 \\
          2x_2 \\
          2x_3
        \end{bmatrix}.
      \end{align*}
      This can also be represented as
      \begin{align*}
        6x_1 - 4x_2 =&\ 2x_1\\
        4x_1 + 2x_2 =&\ 2x_2\\
        -x_1 + 3x_3 =&\ 2x_3,
      \end{align*}
      which is equivalent to
      \begin{align*}
        6x_1 - 2x_1 - 4x_2 =&\ 0\\
        4x_1 + 2x_2 - 2x_2 =&\ 0\\
        -x_1 + 3x_3 - 2x_3 =&\ 0,
      \end{align*}
      i.e.
      \begin{align*}
        4x_1 - 4x_2 =&\ 0\\
        4x_1        =&\ 0\\
        -x_1 +  x_3 =&\ 0.
      \end{align*}
      This is only possible if $x_1 = x_2 = x_3 = 0$.\\

      Next we have
      \begin{align*}
        \begin{bmatrix}
          6 & -4 & 0\\
          4 &  2 & 0\\
         -1 &  0 & 3
        \end{bmatrix}
        \begin{bmatrix}
          x_1 \\
          x_2 \\
          x_3
        \end{bmatrix}
        =
        \begin{bmatrix}
          3x_1 \\
          3x_2 \\
          3x_3
        \end{bmatrix}.
      \end{align*}
      This can also be represented as
      \begin{align*}
        6x_1 - 4x_2 =&\ 3x_1\\
        4x_1 + 2x_2 =&\ 3x_2\\
        -x_1 + 3x_3 =&\ 3x_3,
      \end{align*}
      which is equivalent to
      \begin{align*}
        6x_1 - 3x_1 - 4x_2 =&\ 0\\
        4x_1 + 2x_2 - 3x_2 =&\ 0\\
        -x_1 + 3x_3 - 3x_3 =&\ 0,
      \end{align*}
      i.e.
      \begin{align*}
        3x_1 - 4x_2 =&\ 0\\
        4x_1 -  x_2 =&\ 0\\
        -x_1        =&\ 0.
      \end{align*}
      Again, this is only possible if $x_1 = x_2 = x_3 = 0$.

    \item
      We want to find a row-reduced matrix which is
      row-equivalent to
      \begin{align*}
        A\ & =
        \begin{bmatrix}
          i & -(1 + i) &  0\\
          1 &     -2   &  1\\
          1 &     2i   & -i
        \end{bmatrix}.
      \end{align*}

      \begin{align*}
        \begin{bmatrix}
          i - i & -(1 + i) + 2 & 0 + 1\\
          1 &     -2   &  1\\
          1 &     2i   & -i
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          0 & (1 - i)  &  1\\
          1 &     -2   &  1\\
          1 &     2i   & -i
        \end{bmatrix}
        \xrightarrow{}\\\\
        \begin{bmatrix}
          0 & (1 - i)  &  1\\
          1 &     -2   &  1\\
          1 - 1 & 2i + 2   & -i - 1
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          0 & (1 - i)  &  1\\
          1 &     -2   &  1\\
          0 & (2 + 2i) & -(1 + i)
        \end{bmatrix}
        \xrightarrow{}\\\\
        \begin{bmatrix}
          0 & (1 - i)  &  1\\
          1 &     -2   &  1\\
          0(\frac{1}{4} - \frac{1}{4}i) & (2 + 2i)(\frac{1}{4} - \frac{1}{4}i) & -(1 + i)(\frac{1}{4} - \frac{1}{4}i)
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          0 & (1 - i)  &  1\\
          1 &     -2   &  1\\
          0 & 1 & -\frac{1}{2}
        \end{bmatrix}
        \xrightarrow{}\\\\
        \begin{bmatrix}
          0 & (1 - i) &  1\\
          1 & -2 + 2  &  1 - 1\\
          0 & 1 & -\frac{1}{2}
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          0 & (1 - i) &  1\\
          1 & 0  &  0\\
          0 & 1 & -\frac{1}{2}
        \end{bmatrix}
        \xrightarrow{}\\\\
        \begin{bmatrix}
          0 & (1 - i) - (1 - i) & 1 + (\frac{1}{2} - \frac{1}{2}i)\\
          1 & 0 & 0\\
          0 & 1 & -\frac{1}{2}
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          0 & 0 & (1\frac{1}{2} - \frac{1}{2}i)\\
          1 & 0 & 0\\
          0 & 1 & -\frac{1}{2}
        \end{bmatrix}
        \xrightarrow{}\\\\
        \begin{bmatrix}
          0(\frac{3}{5} + \frac{1}{5}i) & 0(\frac{3}{5} + \frac{1}{5}i) & (1\frac{1}{2} - \frac{1}{2}i)(\frac{3}{5} + \frac{1}{5}i)\\
          1 & 0 & 0\\
          0 & 1 & -\frac{1}{2}
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          0 & 0 & 1\\
          1 & 0 & 0\\
          0 & 1 & -\frac{1}{2}
        \end{bmatrix}
        \xrightarrow{}\\\\
        \begin{bmatrix}
          0 & 0 & 1\\
          1 & 0 & 0\\
          0 + 0 & 1 + 0 & -\frac{1}{2} + \frac{1}{2}
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          0 & 0 & 1\\
          1 & 0 & 0\\
          0 & 1 & 0
        \end{bmatrix}.
      \end{align*}

      Of course, we can map this to
      \begin{align*}
        \begin{bmatrix}
          1 & 0 & 0\\
          0 & 1 & 0\\
          0 & 0 & 1
        \end{bmatrix}
      \end{align*}
      via elementary row operation (3) if we like.

    \item
      We would like to prove that
      \begin{align*}
        \begin{bmatrix}
          2 &  0 & 0\\
          a & -1 & 0\\
          b &  c & 3
        \end{bmatrix}
      \end{align*}
      and
      \begin{align*}
        \begin{bmatrix}
           1 &  1 &  2\\
          -2 &  0 & -1\\
           1 &  3 &  5
        \end{bmatrix}
      \end{align*}
      are \textit{not} row-equivalent.

      \begin{align*}
        \begin{bmatrix}
          2 &  0 & 0\\
          a & -1 & 0\\
          b &  c & 3
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          1 &  0 & 0\\
          a & -1 & 0\\
          b &  c & 3
        \end{bmatrix}
        \xrightarrow{}\\\\
        \begin{bmatrix}
          1 &  0 & 0\\
          0 & -1 & 0\\
          0 &  c & 3
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          1 &  0 & 0\\
          0 &  1 & 0\\
          0 &  c & 3
        \end{bmatrix}
        \xrightarrow{}\\\\
        \begin{bmatrix}
          1 &  0 & 0\\
          0 &  1 & 0\\
          0 &  0 & 3
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          1 &  0 & 0\\
          0 &  1 & 0\\
          0 &  0 & 1
        \end{bmatrix}.
      \end{align*}

      \begin{align*}
        \begin{bmatrix}
           1 &  1 &  2\\
          -2 &  0 & -1\\
           1 &  3 &  5
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
           1     &  1     &  2\\
          -2 + 2 &  0 + 2 & -1 + 4\\
           1     &  3     &  5
        \end{bmatrix}
        \xrightarrow{}\\\\
        \begin{bmatrix}
           1 &  1 &  2\\
           0 &  2 &  3\\
           1 &  3 &  5
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
           1     &  1     &  2\\
           0     &  2     &  3\\
           1 - 1 &  3 - 1 &  5 - 2
        \end{bmatrix}
        \xrightarrow{}\\\\
        \begin{bmatrix}
           1 &  1 &  2\\
           0 &  2 &  3\\
           0 &  2 &  3
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
           1 &  1 &  2\\
           0 &  2 &  3\\
           0 &  0 &  0
        \end{bmatrix}
        \xrightarrow{}\\\\
        \begin{bmatrix}
           1 &  1 &  2\\
           0 &  1 &  1\frac{1}{2}\\
           0 &  0 &  0
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
           1 &  1 - 1 &  2 - 1\frac{1}{2}\\
           0 &  1     &  1\frac{1}{2}\\
           0 &  0     &  0
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
           1 &  0 &  \frac{1}{2}\\
           0 &  1 &  1\frac{1}{2}\\
           0 &  0 &  0
        \end{bmatrix}.
      \end{align*}

      We call
      \begin{align*}
        \begin{bmatrix}
          1 &  0 & 0\\
          0 &  1 & 0\\
          0 &  0 & 1
        \end{bmatrix}
        = A'
      \end{align*}
      and
      \begin{align*}
        \begin{bmatrix}
           1 &  0 &  \frac{1}{2}\\
           0 &  1 &  1\frac{1}{2}\\
           0 &  0 &  0
        \end{bmatrix}
        = B'.
      \end{align*}
      We indicate \say{is row-equivalent to} by $\sim$ and
      \say{is not row-equivalent to} by $\nsim$. We've shown that
      $A \sim A'$ and $B \sim B'$. Therefore, if $A' \sim B'$,
      then $A \sim B$, and otherwise $A \nsim B$, by corollary
      1.1. Because $B'$ has more all-0 rows than $A'$, we know by
      theorem 4 that $A' \nsim B'$, so $A \nsim B$.

    \item
      We let
      \begin{align*}
        A =
        \begin{bmatrix}
           a & b\\
           c & d
        \end{bmatrix}
      \end{align*}
      be a $2 \times 2$ row-reduced matrix with complex entries
      such that $a + b + c + d = 0$. We would like to prove that
      there are exactly three such matrices.

      The possible $2 \times 2$ row-reduced complex matrices are
      \begin{align*}
        \begin{bmatrix}
           1 & 0\\
           0 & 1
        \end{bmatrix},\ 
        \begin{bmatrix}
           0 & 1\\
           1 & 0
        \end{bmatrix},\ 
        \begin{bmatrix}
           1 & p\\
           0 & 0
        \end{bmatrix},\ 
        \begin{bmatrix}
           0 & 0\\
           1 & q
        \end{bmatrix},\ \text{and}\ 
        \begin{bmatrix}
           0 & 0\\
           0 & 0
        \end{bmatrix},
      \end{align*}
      where $p$ and $q$ are complex numbers.

      The first two matrices don't satisfy our condition because
      $a + b + c + d = 2$ in their case. However, if we take $p =
      q = -1$, those forms of the third and fourth matrices will
      satisfy our condition. (However, no other forms of them
      will, because the additive inverse is unique in any field.)
      The last matrix also trivially satisfies our condition.

      Therefore, the three matrices that satisfy our condition
      are
      \begin{align*}
        \begin{bmatrix}
           1 & -1\\
           0 & 0
        \end{bmatrix},\ 
        \begin{bmatrix}
           0 & 0\\
           1 & -1
        \end{bmatrix},\ \text{and}\ 
        \begin{bmatrix}
           0 & 0\\
           0 & 0
        \end{bmatrix}.
      \end{align*}

    \item
      We would like to prove that elementary row operation (3)
      can be accomplished by a finite sequence of (1) and (2).

      We have
      \begin{align*}
        \begin{bmatrix}
          \vdots   & \ddots & \vdots\\
          a_1 & \cdots & a_n\\
          \vdots   & \ddots & \vdots\\
          b_1 & \cdots & b_n\\
          \vdots   & \ddots & \vdots\\
        \end{bmatrix}.
      \end{align*}

      We can proceed as follows:
      \begin{align*}
        \begin{bmatrix}
          \vdots   & \ddots & \vdots\\
          a_1 & \cdots & a_n\\
          \vdots   & \ddots & \vdots\\
          b_1 & \cdots & b_n\\
          \vdots   & \ddots & \vdots\\
        \end{bmatrix}
        \xrightarrow{(2)}
        \begin{bmatrix}
          \vdots   & \ddots & \vdots\\
          a_1 & \cdots & a_n\\
          \vdots   & \ddots & \vdots\\
          b_1 - a_1 & \cdots & b_n - a_n\\
          \vdots   & \ddots & \vdots\\
        \end{bmatrix}
        \xrightarrow{(2)}
      \end{align*}
      \begin{align*}
        \begin{bmatrix}
          \vdots   & \ddots & \vdots\\
          a_1 + (b_1 - a_1) & \cdots & a_n + (b_n - a_n)\\
          \vdots   & \ddots & \vdots\\
          b_1 - a_1 & \cdots & b_n - a_n\\
          \vdots   & \ddots & \vdots\\
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          \vdots   & \ddots & \vdots\\
          b_1 & \cdots & b_n \\
          \vdots   & \ddots & \vdots\\
          b_1 - a_1 & \cdots & b_n - a_n\\
          \vdots   & \ddots & \vdots\\
        \end{bmatrix}
        \xrightarrow{(2)}
      \end{align*}
      \begin{align*}
        \begin{bmatrix}
          \vdots   & \ddots & \vdots\\
          b_1 & \cdots & b_n \\
          \vdots   & \ddots & \vdots\\
          b_1 - a_1 - b_1 & \cdots & b_n - a_n - b_n\\
          \vdots   & \ddots & \vdots\\
        \end{bmatrix}
        \xrightarrow{}
        \begin{bmatrix}
          \vdots   & \ddots & \vdots\\
          b_1 & \cdots & b_n \\
          \vdots   & \ddots & \vdots\\
          - a_1 & \cdots & - a_n \\
          \vdots   & \ddots & \vdots\\
        \end{bmatrix}
        \xrightarrow{(1)}
      \end{align*}
      \begin{align*}
        \begin{bmatrix}
          \vdots   & \ddots & \vdots\\
          b_1 & \cdots & b_n \\
          \vdots   & \ddots & \vdots\\
          a_1 & \cdots & a_n \\
          \vdots   & \ddots & \vdots\\
        \end{bmatrix}.
      \end{align*}
    This completes the proof.

  \item
    We consider the system of equations $AX = 0$ where
    \begin{align*}
      A =
      \begin{bmatrix}
         a & b\\
         c & d
      \end{bmatrix}
    \end{align*}
    is a $2 \times 2$ matrix over a field.
    \begin{enumerate}
        \item
          We would like to prove that if $a = b = c = d = 0$,
          every pair $(x_1,\ x_2)$ is a solution of $AX = 0$.

          This is fairly obvious.
          \begin{align*}
            \begin{bmatrix}
               0 & 0\\
               0 & 0
            \end{bmatrix}
            \begin{bmatrix}
               x_1 \\
               x_2
            \end{bmatrix}
            =
            \begin{bmatrix}
               0 \\
               0
            \end{bmatrix}
          \end{align*}
          can also be represented as
          \begin{align*}
            0x_1 + 0x_2 =&\ 0\\
            0x_1 + 0x_2 =&\ 0,
          \end{align*}
          which is true regardless of the value of $x_1$ or
          $x_2$.

        \item
          We would like to prove that if $ad - bc \neq 0$, the
          system $AX = 0$ has only the trivial solution $x_1 =
          x_2 = 0$.

          We have
          \begin{align*}
            ax_1 + bx_2 =&\ 0\\
            cx_1 + dx_2 =&\ 0.
          \end{align*}

          This implies that
          \begin{align*}
            adx_1 + bdx_2 =&\ 0\\
            bcx_1 + bdx_2 =&\ 0,
          \end{align*}
          and thus that
          \begin{align*}
            adx_1 + bdx_2 - bcx_1 - bdx_2 =&\\
            adx_1 - bcx_1 =&\\
            (ad - bc)x_1 =&\ 0.
          \end{align*}

          We also have that
          \begin{align*}
            acx_1 + bcx_2 =&\ 0\\
            acx_1 + adx_2 =&\ 0,
          \end{align*}
          and thus that
          \begin{align*}
            acx_1 + adx_2 - acx_1 - bcx_2 =&\\
            adx_2 - bcx_2 =&\\
            (ad - bc)x_2 =&\ 0.
          \end{align*}

          Therefore, if $AX = 0$,
          \begin{align*}
            (ad - bc)x_1 =&\ 0\\
            (ad - bc)x_2 =&\ 0.
          \end{align*}
          Because the element $0$ such that $0x = 0$ is unique in
          any field, the only way for these equations to hold if
          $ad - bc \neq 0$ is if $x_1 = x_2 = 0$.

        \item
          We would like to prove that if $ad - bc$ does equal
          $0$, and some entry of $A$ does not equal $0$, there is
          a solution $(x_{1}^{0},\ x_{2}^{0})$, and futhermore
          that any $(x_1,\ x_2)$ is a solution if and only if
          there is some scalar $y$ such that $x_1 = yx_{1}^{0}$
          and $x_2 = x_{2}^{0}$.

          If $ad - bc = 0$, but at least one of $a,\ b,\ c,\ d
          \neq 0$, a few possibilities exist.

          Say that $a \neq 0$ but the other entries do; then this
          equation still holds. In that case, our system boils
          down to $ax_1 = 0$, so $x_1$ must be $0$ but $x_2$ can
          take on any value in the field. So, $(x_{1}^{0},\
          x_{2}^{0}) = (0,1)$ in this case. This is also true if
          $c$ is the only non-zero entry. If $b$ or $d$ is the
          only non-zero entry, $(x_{1}^{0},\ x_{2}^{0}) = (1,0)$
          instead by the same line of reasoning.

          If two or more elements $\neq 0$, then still $ad = bc$;
          otherwise $ad - bc = 0$ wouldn't hold. Consider as we
          showed earlier that there are five possible forms of
          row-reduced $2 \times 2$ matrices over a field:
          \begin{align*}
            \begin{bmatrix}
               1 & 0\\
               0 & 1
            \end{bmatrix},\ 
            \begin{bmatrix}
               0 & 1\\
               1 & 0
            \end{bmatrix},\ 
            \begin{bmatrix}
               1 & p\\
               0 & 0
            \end{bmatrix},\ 
            \begin{bmatrix}
               0 & 0\\
               1 & q
            \end{bmatrix},\ \text{and}\ 
            \begin{bmatrix}
               0 & 0\\
               0 & 0
            \end{bmatrix}.
          \end{align*}
          The last possibility was considered in $(a)$ and isn't
          under consideration here. With the first two
          possibilities, $x_1 = x_2 = 0$ is the only possible
          solution, so $(x_{1}^{0},\ x_{2}^{0}) = (0,0)$ in that
          case. That leaves two remaining, with which we either
          have $ax_1 + bx_2 = 0$ or $cx_1 + dx_2 = 0$ and the
          other equation in the system is trivially true. We
          already covered the case in which only one entry is
          $\neq 0$, so we presume that $p,\ q \neq 0$ at this
          point.

          In the first case, we have $ax_1 = -bx_2$, so $x_2 =
          -\frac{a}{b}x_1$. Likewise, $x_1 = -\frac{b}{a}x_2$.
          So, $(x_{1}^{0},\ x_{2}^{0}) = (1,-\frac{a}{b})$ will
          work, as will $(x_{1}^{0},\ x_{2}^{0}) =
          (-\frac{b}{a},1)$, which is equivalent. In the second
          case, we have $(x_{1}^{0},\ x_{2}^{0}) =
          (1,-\frac{c}{d})$ and $(x_{1}^{0},\ x_{2}^{0}) =
          (-\frac{d}{c},1)$ by the same token.

          So, if $ad - bc = 0$ and at least one of $a,\ b,\ c,\ d
          \neq 0$, the possible values $(x_{1}^{0},\ x_{2}^{0})$
          can take on (depending on the matrix in question) are
          $(0,0)$, $(1,0)$, $(0,1)$, $(1,-\frac{a}{b})$, and
          $(1,-\frac{c}{d})$. This concludes the proof.

          \begin{comm}
            (mine.) Speaking geometrically, since $AX = 0$
            describes a homogeneous system of two lines in 2
            dimensions, $(0,0)$ corresponds to the case where
            they intersect only at the origin, $(1,0)$
            corresponds to the case where they both overlap the
            $x_1$-axis, $(0,1)$ corresponds to the case where
            they both overlap the $x_2$-axis, and
            $(1,-\frac{a}{b})$ and $(1,-\frac{c}{d})$ correspond
            to the case in which both lines overlap and don't lie
            on either axis. It's worth noting that if $A$ is
            mapped to row-reduced echelon form, there will be
            only $(1,-\frac{a}{b})$, which is more geometrically
            natural as both lines are the same in that case. If
            this line is expressed as $y = -\frac{a}{b}x$, i.e.
            by assigning a horizontal and vertical orientation to
            $x_1$ and $x_2$, $-\frac{a}{b}$ gives the slope of
            this line.
          \end{comm}
    \end{enumerate}

\end{enumerate}

\end{document}
